# Welcome to ChatterEngine

This project is my attempt to learn how to build my own **Speech-to-Speech Translation Engine**, completely open and modular.

### ğŸ¯ Use Case

The goal is to develop a **speech-to-speech translation system** with an optional **text output feature**, supporting Swedish â†’ English.

---

## ğŸš€ Goals

### ğŸ”Š Speech Recognition (STT)

- [Speech Recognition Phonetics â€“ Jonathan Hui](https://jonathan-hui.medium.com/speech-recognition-phonetics-d761ea1710c0)
- [Build an End-to-End STT Model â€“ Symbl.ai](https://symbl.ai/developers/blog/a-guide-to-building-an-end-to-end-speech-recognition-model/)
- [Analytics Vidhya STT Guide](https://www.analyticsvidhya.com/blog/2019/07/learn-build-first-speech-to-text-model-python/)
- [ESPnet](https://github.com/espnet/espnet) | [Fairseq + Wav2Vec 2.0](https://github.com/facebookresearch/fairseq)

### ğŸŒ Machine Translation (NMT)

- [Natural Language Processing is Fun!](https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e)
- [OPUS Corpus](https://opus.nlpl.eu/)
- [Fairseq](https://github.com/facebookresearch/fairseq) | [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)

### ğŸ—£ï¸ Text-to-Speech (TTS)

- Exploring methods like Tacotron2, FastSpeech2, HiFi-GAN
- [ESPnet TTS](https://espnet.github.io/espnet/tts.html)
- [Coqui TTS](https://github.com/coqui-ai/TTS)

---

## ğŸ› ï¸ Process Overview

**Speech Recognition** â†’ **Machine Translation** â†’ **Text-to-Speech Synthesis**

This project will combine **automatic speech recognition (ASR)**, **neural machine translation**, and **text-to-speech synthesis** to create a seamless translation system.

---

## ğŸ“Œ Detailed Roadmap

### ğŸ¤ 1. Speech-to-Text (STT)

#### ğŸ“š Learn

- Audio features: MFCC, mel spectrograms
- CTC vs attention-based models
- Transformers (Conformer)
- Evaluation: WER

#### ğŸ§ª Build

- Load and preprocess audio with `torchaudio`
- Extract features and train CTC model (LSTM)
- Evaluate with greedy decoding

#### ğŸš€ Extend

- Use ESPnet or NeMo for larger models
- Add language model (KenLM or transformer-based)
- Train on Swedish Common Voice

#### âš™ï¸ Deploy

- TorchScript or ONNX export
- Real-time decoder module

---

### ğŸŒ 2. Neural Machine Translation (NMT)

#### ğŸ“š Learn

- Seq2Seq, attention, Transformer models
- Tokenization (BPE) using SentencePiece
- Evaluation: BLEU, chrF

#### ğŸ§ª Build

- Download parallel corpora (Swedish-English)
- Preprocess, tokenize, apply BPE
- Train transformer using Fairseq or OpenNMT

#### ğŸš€ Extend

- Integrate pretrained embeddings or multilingual transformers
- Tune hyperparameters and layers

#### âš™ï¸ Deploy

- TorchScript model
- Expose as translation microservice

---

### ğŸ—£ï¸ 3. Text-to-Speech (TTS)

#### ğŸ“š Learn

- Text normalization, G2P
- Tacotron2 / FastSpeech2 (text â†’ mel)
- Vocoder: Griffin-Lim, WaveGlow, HiFi-GAN

#### ğŸ§ª Build

- Train Tacotron2 on LJSpeech
- Generate audio using HiFi-GAN

#### ğŸš€ Extend

- Fine-tune on custom speaker
- Add prosody control (style tokens)

#### âš™ï¸ Deploy

- Export model (ONNX)
- Stream audio output as a service

---

## ğŸ“¦ Datasets

| Type | Dataset                         | Language | Notes                |
| ---- | ------------------------------- | -------- | -------------------- |
| STT  | Common Voice                    | Swedish  | Main STT source      |
| STT  | LibriSpeech                     | English  | Benchmark reference  |
| NMT  | OPUS (Tatoeba, Europarl, JW300) | Sv-En    | Parallel text        |
| TTS  | LJSpeech                        | English  | Clean single-speaker |
| TTS  | VCTK                            | English  | Multi-speaker voices |

---

## ğŸ§° Key Tools and Frameworks

| Area     | Tool                | Purpose                          |
| -------- | ------------------- | -------------------------------- |
| STT      | ESPnet              | End-to-end pipeline with recipes |
| STT      | Fairseq (Wav2Vec2)  | Self-supervised pretraining      |
| NMT      | Fairseq / OpenNMT   | Transformer training             |
| TTS      | ESPnet-TTS / Coqui  | Tacotron2, FastSpeech2, vocoders |
| Audio    | torchaudio / ffmpeg | Preprocessing and transforms     |
| Export   | ONNX / TorchScript  | Model deployment                 |
| Training | PyTorch / Lightning | Core ML framework                |

---

## ğŸ“‚ Project Modules (Planned)

chatterengine/
â”œâ”€â”€ stt/ # Speech recognition module
â”œâ”€â”€ nmt/ # Translation module
â”œâ”€â”€ tts/ # Text-to-speech module
â”œâ”€â”€ data/ # Raw + preprocessed data
â”œâ”€â”€ utils/ # Feature extraction, tokenization, logging
â”œâ”€â”€ scripts/ # Training, evaluation, conversion
â””â”€â”€ serve/ # Microservices for runtime

---

## ğŸ”„ Integration Plan

```text
Audio (Swedish)
    â†“
[ STT Module ] â†’ Swedish Text
    â†“
[ NMT Module ] â†’ English Text
    â†“
[ TTS Module ] â†’ English Speech
```
